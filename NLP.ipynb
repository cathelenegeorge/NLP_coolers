{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaVrUzVnc44eFWlCTt1UWa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cathelenegeorge/NLP_coolers/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise : 1 Word Analysis\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "from nltk.probability import FreqDist\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"stopwords\")\n",
        "text = \"Natural Language Processing is an Interesting field of AI\"\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens : \\n\",tokens)\n",
        "print(\"\\n\")\n",
        "stemmer = PorterStemmer()\n",
        "stw = [stemmer.stem(word) for word in tokens]\n",
        "print(\"Stemmend Words : \\n\",stw)\n",
        "print(\"\\n\")\n",
        "lemma = WordNetLemmatizer()\n",
        "lem = [lemma.lemmatize(word) for word in tokens]\n",
        "print(\"Lemmatized Words : \\n\",lem)\n",
        "print(\"\\n\")\n",
        "freq = FreqDist(tokens)\n",
        "print(\"Frequency Distribution : \\n\",freq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MvU3OqJmV-q",
        "outputId": "4c0a6d35-cea5-4c25-98de-865a77443dce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens : \n",
            " ['Natural', 'Language', 'Processing', 'is', 'an', 'Interesting', 'field', 'of', 'AI']\n",
            "\n",
            "\n",
            "Stemmend Words : \n",
            " ['natur', 'languag', 'process', 'is', 'an', 'interest', 'field', 'of', 'ai']\n",
            "\n",
            "\n",
            "Lemmatized Words : \n",
            " ['Natural', 'Language', 'Processing', 'is', 'an', 'Interesting', 'field', 'of', 'AI']\n",
            "\n",
            "\n",
            "Frequency Distribution : \n",
            " <FreqDist with 9 samples and 9 outcomes>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS4OGp5VF_V8",
        "outputId": "163b11e8-944e-4c1f-b608-869085efc40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens : \n",
            " ['Natural', 'Language', 'Processing', 'is', 'an', 'interesting', 'field', 'of', 'AI']\n",
            "\n",
            "\n",
            "Bigrams : \n",
            " [('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'is'), ('is', 'an'), ('an', 'interesting'), ('interesting', 'field'), ('field', 'of'), ('of', 'AI')]\n",
            "\n",
            "\n",
            "Trigrams :\n",
            " [('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'is'), ('Processing', 'is', 'an'), ('is', 'an', 'interesting'), ('an', 'interesting', 'field'), ('interesting', 'field', 'of'), ('field', 'of', 'AI')]\n",
            "Generated Text :  Natural Language Processing is an interesting field of AI\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Exercise : 2 Word Generation\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import bigrams, trigrams\n",
        "import random\n",
        "\n",
        "nltk.download(\"punkt_tab\")\n",
        "text = \"Natural Language Processing is an interesting field of AI\"\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens : \\n\", tokens)\n",
        "print(\"\\n\")\n",
        "bigrams = list(bigrams(tokens))\n",
        "print(\"Bigrams : \\n\", bigrams)\n",
        "print(\"\\n\")\n",
        "trigrams = list(trigrams(tokens))\n",
        "print(\"Trigrams :\\n\", trigrams)\n",
        "\n",
        "\n",
        "def generate_text(bigrams, start_word, length=10):\n",
        "    word = start_word\n",
        "    generated_text = [word]\n",
        "    for i in range(length):\n",
        "        next_word = [pair[1] for pair in bigrams if pair[0] == word]\n",
        "        if not next_word:\n",
        "            break\n",
        "        word = random.choice(next_word)\n",
        "        generated_text.append(word)\n",
        "    return \" \".join(generated_text)\n",
        "\n",
        "\n",
        "print(\"Generated Text : \", generate_text(bigrams, \"Natural\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise : 3 Text Classification\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = [\"The movie is good\",\"The movie is bad\",\"The movie is not bad\",\"The movie is not good\"]\n",
        "label = [\"positive\",\"negative\",\"negative\",\"positive\"]\n",
        "cv = CountVectorizer()\n",
        "X =cv.fit_transform(X)\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,label,test_size = 0.25,random_state = 42)\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train,Y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy :\",accuracy_score(Y_test,y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1S-ELoxLmVc",
        "outputId": "8cc6d26b-a76d-46d3-a943-7919ffe867a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise :4 Semantic Analysis\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "sentences = [\"Natural language Processing is fun \",\"I love AI\"]\n",
        "tokenized_sentence =[sentence.lower().split() for sentence in sentences]\n",
        "model = Word2Vec(sentences = tokenized_sentence,vector_size = 50,min_count = 1)\n",
        "word_vector = model.wv[\"natural\"]\n",
        "print(\"Word Vector for Natural :\",word_vector)\n",
        "similar_words = model.wv.most_similar(\"natural\")\n",
        "print(\"Similar Words to Natural :\",similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRJK_6GkNSH0",
        "outputId": "99cb79f1-e0d6-4a2a-f250-630816d8d922"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Vector for Natural : [ 0.00855287  0.00015212 -0.01916856 -0.01933109 -0.01229639 -0.00025714\n",
            "  0.00399483  0.01886394  0.0111687  -0.00858139  0.00055663  0.00992872\n",
            "  0.01539662 -0.00228845  0.00864684 -0.01162876 -0.00160838  0.0162001\n",
            " -0.00472013 -0.01932691  0.01155852 -0.00785964 -0.00244575  0.01996103\n",
            " -0.0045127  -0.00951413 -0.01065877  0.01396178 -0.01141774  0.00422733\n",
            " -0.01051132  0.01224143  0.00871461  0.00521271 -0.00298217 -0.00549213\n",
            "  0.01798587  0.01043155 -0.00432504 -0.01894062 -0.0148521  -0.00212748\n",
            " -0.00158989 -0.00512582  0.01936544 -0.00091704  0.01174752 -0.01489517\n",
            " -0.00501215 -0.01109973]\n",
            "Similar Words to Natural : [('is', 0.13661059737205505), ('ai', 0.13204392790794373), ('language', 0.11253627389669418), ('fun', 0.04491730034351349), ('processing', 0.029594358056783676), ('love', -0.1754782348871231), ('i', -0.21872937679290771)]\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Exercise : 5 Sentiment Analysis\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "text = [\"I love this product\",\"Never buy it ever again\",\"Not that great\",\"Its Excellent\"]\n",
        "label = [1,0,0,1]\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(text)\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,label,test_size = 0.5,random_state = 42)\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train,y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "print(\"Accuracy :\",accuracy_score(y_test,y_pred))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oxIS638KPFW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62331c55-59b8-4918-c1e0-dcd90751f8f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise : 6 POS Tagging\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
        "from nltk import pos_tag\n",
        "text = \"Natural Language Processing is an interesting field of AI\"\n",
        "tokens = word_tokenize(text)\n",
        "pos_tags = pos_tag(tokens)\n",
        "print(\"POS Tags :\",pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uYBAIeZSpOd",
        "outputId": "2193dff3-5b52-4290-d6d6-77d52412183f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags : [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('interesting', 'JJ'), ('field', 'NN'), ('of', 'IN'), ('AI', 'NNP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise : 7: Chunking\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag, RegexpParser\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "\n",
        "text = \"Natural Language Processing is an interesting field of AI\"\n",
        "tokens = word_tokenize(text)\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "print(\"POS Tags:\")\n",
        "print(pos_tags)\n",
        "\n",
        "grammar = r\"\"\"\n",
        "  NP: {<DT>?<JJ>*<NN>}   # Determiner + adjectives (optional) + noun\n",
        "      {<NNP>+}           # Proper nouns\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "chunk_parser = RegexpParser(grammar)\n",
        "tree = chunk_parser.parse(pos_tags)\n",
        "print(\"\\nChunked Tree:\")\n",
        "print(tree)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqQynT3gfyiw",
        "outputId": "3dd04279-52ff-4965-e168-cd361968ddb9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags:\n",
            "[('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('interesting', 'JJ'), ('field', 'NN'), ('of', 'IN'), ('AI', 'NNP')]\n",
            "\n",
            "Chunked Tree:\n",
            "(S\n",
            "  Natural/JJ\n",
            "  (NP Language/NNP Processing/NNP)\n",
            "  is/VBZ\n",
            "  (NP an/DT interesting/JJ field/NN)\n",
            "  of/IN\n",
            "  (NP AI/NNP))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    }
  ]
}